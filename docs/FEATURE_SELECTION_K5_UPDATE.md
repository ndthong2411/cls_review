# Cáº­p Nháº­t: ThÃªm Feature Selection k=5

## Tá»•ng Quan

ÄÃ£ cáº­p nháº­t `full_comparison.py` Ä‘á»ƒ thÃªm cáº¥u hÃ¬nh feature selection vá»›i **k=5** (chá»n 5 features quan trá»ng nháº¥t) vÃ o experiment matrix. Äiá»u nÃ y cho phÃ©p so sÃ¡nh hiá»‡u suáº¥t giá»¯a:
- Sá»­ dá»¥ng táº¥t cáº£ features (none)
- Sá»­ dá»¥ng 5 features tá»‘t nháº¥t (select_k_best_5) â­ Má»šI
- Sá»­ dá»¥ng 12 features tá»‘t nháº¥t (select_k_best_12)

## Thay Äá»•i Code

### File: `full_comparison.py` (dÃ²ng 1140)

**TrÆ°á»›c:**
```python
for scaler, imbalance, feat_sel in product(
    scalers,
    ['none', 'smote', 'smote_enn'],
    ['none', 'select_k_best_12']  # Chá»‰ cÃ³ 2 options
):
```

**Sau:**
```python
for scaler, imbalance, feat_sel in product(
    scalers,
    ['none', 'smote', 'smote_enn'],
    ['none', 'select_k_best_5', 'select_k_best_12']  # ThÃªm select_k_best_5
):
```

## So SÃ¡nh Sá»‘ LÆ°á»£ng Experiments

| Metric | TrÆ°á»›c | Sau | Thay Äá»•i |
|--------|-------|-----|----------|
| **Models cáº§n scaling** | 5 models | 5 models | - |
| **Scalers** (cho models cáº§n scaling) | 2 (standard, robust) | 2 | - |
| **Imbalance methods** | 3 (none, smote, smote_enn) | 3 | - |
| **Feature selection** | 2 (none, k=12) | 3 (none, k=5, k=12) | +1 â­ |
| | | | |
| **Experiments (scaling models)** | 5Ã—2Ã—3Ã—2 = 60 | 5Ã—2Ã—3Ã—3 = 90 | +30 |
| **Experiments (non-scaling models)** | 8Ã—1Ã—3Ã—2 = 48 | 8Ã—1Ã—3Ã—3 = 72 | +24 |
| **Tá»”NG EXPERIMENTS** | **108** | **162** | **+54 (+50%)** |

## Thá»i Gian Æ¯á»›c TÃ­nh

Vá»›i thá»i gian trung bÃ¬nh ~45 giÃ¢y má»—i experiment:

| | TrÆ°á»›c | Sau | ThÃªm |
|---|-------|-----|------|
| **Tá»•ng thá»i gian** | ~81 phÃºt | ~122 phÃºt | +40 phÃºt |
| **TÃ­nh theo giá»** | ~1.4 giá» | ~2.0 giá» | +0.6 giá» |

**LÆ°u Ã½:** Thá»i gian thá»±c táº¿ cÃ³ thá»ƒ thay Ä‘á»•i tÃ¹y thuá»™c vÃ o:
- Dataset size (cardio: 70k rows, creditcard: 285k rows)
- Model complexity (Gen4 models cháº­m hÆ¡n Gen1)
- Hardware (GPU availability)
- Cache hits (cached experiments khÃ´ng cáº§n train láº¡i)

## Feature Selection Methods

### 1. `none` - KhÃ´ng Feature Selection
- Sá»­ dá»¥ng **Táº¤T Cáº¢** features
- Cardio dataset: 15 features
- Creditcard dataset: 30 features
- **Æ¯u Ä‘iá»ƒm:** KhÃ´ng máº¥t thÃ´ng tin
- **NhÆ°á»£c Ä‘iá»ƒm:** CÃ³ thá»ƒ overfitting, cháº­m hÆ¡n

### 2. `select_k_best_5` - Top 5 Features â­ Má»šI
- Chá»n **5 features quan trá»ng nháº¥t** dá»±a trÃªn F-statistic
- **Æ¯u Ä‘iá»ƒm:** 
  - Ráº¥t nhanh (Ã­t features)
  - Giáº£m overfitting
  - Dá»… interpret
  - Tá»‘t cho models Ä‘Æ¡n giáº£n
- **NhÆ°á»£c Ä‘iá»ƒm:** 
  - CÃ³ thá»ƒ máº¥t thÃ´ng tin quan trá»ng
  - KhÃ´ng tá»‘t cho dataset phá»©c táº¡p

### 3. `select_k_best_12` - Top 12 Features
- Chá»n **12 features quan trá»ng nháº¥t**
- **Æ¯u Ä‘iá»ƒm:**
  - Balance giá»¯a performance vÃ  simplicity
  - Giá»¯ Ä‘Æ°á»£c nhiá»u thÃ´ng tin
  - Váº«n giáº£m Ä‘Æ°á»£c noise
- **NhÆ°á»£c Ä‘iá»ƒm:**
  - CÃ³ thá»ƒ váº«n hÆ¡i phá»©c táº¡p cho má»™t sá»‘ models

## Lá»£i Ãch

### 1. ğŸ” TÃ¬m Sá»‘ LÆ°á»£ng Features Tá»‘i Æ¯u
So sÃ¡nh trá»±c tiáº¿p hiá»‡u suáº¥t vá»›i 3 má»©c Ä‘á»™ feature selection khÃ¡c nhau Ä‘á»ƒ tÃ¬m balance tá»‘t nháº¥t.

### 2. ğŸ“Š Hiá»ƒu Feature Importance
- Features nÃ o Ä‘Æ°á»£c chá»n trong top 5?
- Features nÃ o trong top 12 nhÆ°ng khÃ´ng trong top 5?
- Liá»‡u 5 features cÃ³ Ä‘á»§ Ä‘á»ƒ Ä‘áº¡t performance tá»‘t?

### 3. âš¡ Performance vs Complexity
- Model vá»›i 5 features: nhanh, Ä‘Æ¡n giáº£n, dá»… deploy
- Model vá»›i 12 features: máº¡nh hÆ¡n nhÆ°ng phá»©c táº¡p hÆ¡n
- Model vá»›i all features: máº¡nh nháº¥t nhÆ°ng cÃ³ thá»ƒ overfit

### 4. ğŸ¯ Tá»‘i Æ¯u Cho Use Case
- **Production deployment:** Æ¯u tiÃªn k=5 (nhanh, Ä‘Æ¡n giáº£n)
- **Research/Analysis:** Æ¯u tiÃªn all features (Ä‘áº§y Ä‘á»§ thÃ´ng tin)
- **Balance:** Æ¯u tiÃªn k=12 (compromise tá»‘t)

## VÃ­ Dá»¥ Experiments Má»›i

### Cardio Dataset
```
Gen1_LogisticRegression | Scale=standard | Imb=none | FeatSel=select_k_best_5
Gen1_LogisticRegression | Scale=standard | Imb=smote | FeatSel=select_k_best_5
Gen1_LogisticRegression | Scale=standard | Imb=smote_enn | FeatSel=select_k_best_5
Gen1_LogisticRegression | Scale=robust | Imb=none | FeatSel=select_k_best_5
...
Gen1_KNN | Scale=standard | Imb=none | FeatSel=select_k_best_5
...
Gen4_TabNet | Scale=none | Imb=smote_enn | FeatSel=select_k_best_5
```

Má»—i model sáº½ cÃ³ thÃªm 54 configurations vá»›i `select_k_best_5`.

## Káº¿t Quáº£ Mong Äá»£i

### Top Performers (Dá»± ÄoÃ¡n)

**Scenario 1: k=5 Wins**
```
Model: Gen1_KNN
Config: robust / smote_enn / select_k_best_5
PR-AUC: 0.8150
â†’ Chá»©ng tá» 5 features quan trá»ng lÃ  Ä‘á»§!
```

**Scenario 2: k=12 Wins**
```
Model: Gen3_XGBoost
Config: none / smote / select_k_best_12
PR-AUC: 0.8200
â†’ Cáº§n nhiá»u features hÆ¡n cho performance tá»‘t nháº¥t
```

**Scenario 3: All Features Wins**
```
Model: Gen4_PyTorch_MLP
Config: standard / none / none
PR-AUC: 0.8250
â†’ Deep learning táº­n dá»¥ng tá»‘t nhiá»u features
```

## So SÃ¡nh Chi Tiáº¿t

### Expected Feature Selection Impact

| Dataset | Total Features | k=5 | k=12 | All |
|---------|---------------|-----|------|-----|
| **Cardio** | 15 | 33% | 80% | 100% |
| **Creditcard** | 30 | 17% | 40% | 100% |

### Model Type Predictions

| Model Type | Best k | LÃ½ Do |
|------------|--------|-------|
| **Simple (Gen1)** | k=5 hoáº·c k=12 | TrÃ¡nh overfitting |
| **Ensemble (Gen2)** | k=12 hoáº·c all | Handle Ä‘Æ°á»£c nhiá»u features |
| **Boosting (Gen3)** | k=12 hoáº·c all | Feature importance tá»± Ä‘á»™ng |
| **Deep Learning (Gen4)** | all | Há»c Ä‘Æ°á»£c feature interactions |

## CÃ¡ch PhÃ¢n TÃ­ch Káº¿t Quáº£

### 1. So SÃ¡nh Trong CÃ¹ng Model
```python
# VÃ­ dá»¥: Gen1_LogisticRegression
df[df['model'] == 'Gen1_LogisticRegression'].groupby('feature_selection')['pr_auc'].mean()

# Output:
# none               0.7580
# select_k_best_5    0.7650  â† Tá»‘t hÆ¡n vá»›i k=5!
# select_k_best_12   0.7620
```

### 2. So SÃ¡nh Across Models
```python
# Model nÃ o benefit nháº¥t tá»« feature selection?
best_by_feat_sel = df.groupby(['model', 'feature_selection'])['pr_auc'].max().unstack()
best_by_feat_sel['best_k'] = best_by_feat_sel.idxmax(axis=1)
```

### 3. TÃ¬m Sweet Spot
```python
# Sá»‘ features tá»‘i Æ°u cho tá»«ng generation?
df.groupby(['generation', 'feature_selection'])['pr_auc'].mean()
```

## Running the Experiments

### Cháº¡y Äáº§y Äá»§
```bash
# Cardio dataset
python full_comparison.py --data data/raw/cardio_train.csv

# Creditcard dataset
python full_comparison.py --data data/raw/creditcard.csv
```

### Cháº¡y Vá»›i Cache
```bash
# Náº¿u Ä‘Ã£ cháº¡y trÆ°á»›c Ä‘Ã³, cached experiments sáº½ Ä‘Æ°á»£c load
python full_comparison.py --data data/raw/cardio_train.csv
# Output: "âœ“ Loaded from cache!" cho cÃ¡c experiments Ä‘Ã£ train
```

### Cháº¡y KhÃ´ng Cache (Train Láº¡i Táº¥t Cáº£)
```bash
python full_comparison.py --data data/raw/cardio_train.csv --no-cache
```

## Cache Organization

Cache directory structure giá» sáº½ bao gá»“m cáº£ k=5:

```
experiments/model_cache/
â”œâ”€â”€ cardio_train/
â”‚   â”œâ”€â”€ Gen1_KNN_standard_smote_none_abc123.pkl
â”‚   â”œâ”€â”€ Gen1_KNN_standard_smote_select_k_best_5_def456.pkl  â­ NEW
â”‚   â”œâ”€â”€ Gen1_KNN_standard_smote_select_k_best_12_ghi789.pkl
â”‚   â””â”€â”€ ...
â””â”€â”€ creditcard/
    â”œâ”€â”€ Gen1_KNN_standard_smote_none_xyz123.pkl
    â”œâ”€â”€ Gen1_KNN_standard_smote_select_k_best_5_uvw456.pkl  â­ NEW
    â””â”€â”€ ...
```

## Troubleshooting

### Q: "ValueError: k should be >=0 and <= n_features"
**A:** Xáº£y ra khi k > sá»‘ features. 
- Cardio: 15 features â†’ k=5 OK, k=12 OK
- Creditcard: 30 features â†’ k=5 OK, k=12 OK
- Náº¿u dataset cÃ³ < 5 features, cáº§n giáº£m k

### Q: Thá»i gian cháº¡y quÃ¡ lÃ¢u?
**A:** Má»™t sá»‘ tÃ¹y chá»n:
- Cháº¡y vá»›i cache enabled (máº·c Ä‘á»‹nh)
- Chá»‰ cháº¡y má»™t subset models
- Sá»­ dá»¥ng GPU (náº¿u cÃ³)

### Q: LÃ m sao biáº¿t k nÃ o tá»‘t nháº¥t?
**A:** Xem TOP 10 trong results:
```bash
python analyze_results.py experiments/full_comparison/cardio_train/full_comparison_*.csv
```

## TÃ³m Táº¯t

âœ… **ÄÃ£ thÃªm:** `select_k_best_5` vÃ o experiment matrix  
âœ… **Tá»•ng experiments:** 108 â†’ 162 (+54)  
âœ… **Thá»i gian thÃªm:** ~40 phÃºt  
âœ… **Lá»£i Ã­ch:** So sÃ¡nh 3 levels cá»§a feature selection  
âœ… **Compatible:** Hoáº¡t Ä‘á»™ng vá»›i cáº£ cardio vÃ  creditcard datasets  
âœ… **Cache-friendly:** Chá»‰ train experiments má»›i, reuse cache cÅ©  

---

**Date:** 2025-10-16  
**File Modified:** `full_comparison.py`  
**Lines Changed:** 1140  
