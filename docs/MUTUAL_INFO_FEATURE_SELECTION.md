# ThÃªm Mutual Information Feature Selection

**NgÃ y cáº­p nháº­t:** 2025-10-16  
**File thay Ä‘á»•i:** `full_comparison.py`  
**TÃ¡c giáº£:** System Update

---

## ğŸ“Š Tá»•ng Quan

ÄÃ£ thÃªm **Mutual Information** lÃ m phÆ°Æ¡ng phÃ¡p feature selection thá»© hai Ä‘á»ƒ so sÃ¡nh vá»›i ANOVA F-test. Äiá»u nÃ y cho phÃ©p phÃ¡t hiá»‡n cáº£ má»‘i quan há»‡ **phi tuyáº¿n** giá»¯a features vÃ  target.

## ğŸ”„ CÃ¡c Thay Äá»•i

### 1. Import Libraries (dÃ²ng 48)
```python
# TrÆ°á»›c:
from sklearn.feature_selection import SelectKBest, f_classif, RFE

# Sau:
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE
```

### 2. Feature Selection Config (dÃ²ng 93-98)
```python
# TrÆ°á»›c:
FEATURE_SELECTION_METHODS = {
    'none': None,
    'select_k_best_5': SelectKBest(f_classif, k=5),
    'select_k_best_12': SelectKBest(f_classif, k=12),
}

# Sau:
FEATURE_SELECTION_METHODS = {
    'none': None,
    'select_k_best_5': SelectKBest(f_classif, k=5),
    'select_k_best_12': SelectKBest(f_classif, k=12),
    'mutual_info_5': SelectKBest(mutual_info_classif, k=5),    # â­ Má»šI
    'mutual_info_12': SelectKBest(mutual_info_classif, k=12),  # â­ Má»šI
}
```

### 3. Experiment Matrix (dÃ²ng 1141)
```python
# TrÆ°á»›c:
['none', 'select_k_best_5', 'select_k_best_12']

# Sau:
['none', 'select_k_best_5', 'select_k_best_12', 'mutual_info_5', 'mutual_info_12']
```

## ğŸ“ˆ Sá»‘ LÆ°á»£ng Experiments

| Stage | Feature Selection Methods | Total Experiments | Change |
|-------|--------------------------|-------------------|--------|
| **Baseline** | 2 (none, k=12) | 108 | - |
| **+ K=5** | 3 (none, k=5, k=12) | 162 | +54 (+50%) |
| **+ Mutual Info** | 5 (all above + mi=5, mi=12) | **270** | **+108 (+67%)** |

### Breakdown

| Model Type | Scalers | Imbalance | Feature Sel | Per Model | Total |
|-----------|---------|-----------|-------------|-----------|-------|
| **Scaling (5 models)** | 2 | 3 | 5 | 30 | 150 |
| **Non-scaling (8 models)** | 1 | 3 | 5 | 15 | 120 |
| **TOTAL** | - | - | - | - | **270** |

## â±ï¸ Thá»i Gian Æ¯á»›c TÃ­nh

| Configuration | Time (minutes) | Time (hours) | Additional |
|--------------|----------------|--------------|------------|
| Baseline (2 methods) | 81 | 1.4 | - |
| + K=5 (3 methods) | 122 | 2.0 | +41 min |
| + Mutual Info (5 methods) | **203** | **3.4** | **+81 min** |

**LÆ°u Ã½:** Vá»›i cache enabled, chá»‰ experiments má»›i cáº§n train!

## ğŸ¯ 5 Feature Selection Methods

| # | Method | Algorithm | K | Description |
|---|--------|-----------|---|-------------|
| 1 | `none` | - | All | KhÃ´ng feature selection |
| 2 | `select_k_best_5` | ANOVA F-test | 5 | Top 5 features (linear) |
| 3 | `select_k_best_12` | ANOVA F-test | 12 | Top 12 features (linear) |
| 4 | `mutual_info_5` â­ | Mutual Information | 5 | Top 5 features (non-linear) |
| 5 | `mutual_info_12` â­ | Mutual Information | 12 | Top 12 features (non-linear) |

## ğŸ”¬ ANOVA F-test vs Mutual Information

### So SÃ¡nh Chi Tiáº¿t

| Äáº·c Äiá»ƒm | ANOVA F-test | Mutual Information |
|----------|--------------|-------------------|
| **Má»‘i quan há»‡** | Chá»‰ tuyáº¿n tÃ­nh | Tuyáº¿n tÃ­nh + Phi tuyáº¿n |
| **Tá»‘c Ä‘á»™** | Ráº¥t nhanh âš¡ | Cháº­m hÆ¡n ğŸ¢ |
| **Äá»™ phá»©c táº¡p** | O(n) | O(n log n) |
| **Giáº£ Ä‘á»‹nh** | PhÃ¢n phá»‘i chuáº©n | KhÃ´ng giáº£ Ä‘á»‹nh |
| **á»”n Ä‘á»‹nh** | Ráº¥t á»•n Ä‘á»‹nh | CÃ³ thá»ƒ dao Ä‘á»™ng |
| **Pattern phá»©c táº¡p** | âŒ KhÃ´ng | âœ… CÃ³ |
| **TÆ°Æ¡ng tÃ¡c features** | âŒ KhÃ´ng | âœ… Má»™t pháº§n |

### CÃ´ng Thá»©c

#### ANOVA F-test
```
F = (Variance between classes) / (Variance within classes)

F cÃ ng cao â†’ Feature cÃ ng phÃ¢n biá»‡t Ä‘Æ°á»£c classes
```

#### Mutual Information
```
MI(X, Y) = H(X) + H(Y) - H(X,Y)

Trong Ä‘Ã³:
- H(X): Entropy cá»§a feature X
- H(Y): Entropy cá»§a target Y  
- H(X,Y): Joint entropy

MI cÃ ng cao â†’ X vÃ  Y cÃ ng phá»¥ thuá»™c vÃ o nhau
```

### VÃ­ Dá»¥ Minh Há»a

```python
import numpy as np

# Feature 1: Linear relationship
x1 = np.array([1, 2, 3, 4, 5])
y = np.array([0, 0, 1, 1, 1])
# ANOVA: HIGH âœ…  |  MI: HIGH âœ…

# Feature 2: Non-linear (quadratic)
x2 = np.array([1, 4, 9, 16, 25])  # x^2
y = np.array([0, 0, 1, 1, 1])
# ANOVA: LOW âŒ  |  MI: HIGH âœ…  â† Chá»‰ MI phÃ¡t hiá»‡n Ä‘Æ°á»£c!

# Feature 3: Noise
x3 = np.random.randn(5)
y = np.array([0, 0, 1, 1, 1])
# ANOVA: LOW âœ…  |  MI: LOW âœ…
```

## ğŸ’¡ Khi NÃ o DÃ¹ng Method NÃ o?

### DÃ¹ng ANOVA F-test khi:
âœ… Dá»¯ liá»‡u cÃ³ phÃ¢n phá»‘i chuáº©n  
âœ… Quan há»‡ tuyáº¿n tÃ­nh  
âœ… Cáº§n tá»‘c Ä‘á»™ nhanh  
âœ… Dataset lá»›n (>100k rows)  
âœ… Features Ä‘Ã£ Ä‘Æ°á»£c scale/normalize  

**PhÃ¹ há»£p vá»›i:**
- Simple models (Logistic Regression, Linear SVM)
- Preprocessed features (PCA components)
- Initial exploration

### DÃ¹ng Mutual Information khi:
âœ… Quan há»‡ phi tuyáº¿n  
âœ… KhÃ´ng giáº£ Ä‘á»‹nh phÃ¢n phá»‘i  
âœ… Features phá»©c táº¡p (interactions)  
âœ… Dataset vá»«a (<50k rows)  
âœ… Cáº§n robust feature selection  

**PhÃ¹ há»£p vá»›i:**
- Complex models (Random Forest, XGBoost)
- Raw features (before transformation)
- Medical/Biological data
- **Credit Card Fraud** (non-linear fraud patterns)
- **Cardiovascular** (complex health interactions)

## ğŸ¯ á»¨ng Dá»¥ng Vá»›i Datasets

### Credit Card Fraud Dataset
```python
# Features: V1-V28 (PCA components) + Time + Amount
# Total: 30 features

# ANOVA F-test:
- Tá»‘t cho V1-V28 (PCA Ä‘Ã£ tuyáº¿n tÃ­nh hÃ³a)
- Nhanh vá»›i 285k rows

# Mutual Information:
- Tá»‘t cho Time & Amount (non-linear patterns)
- PhÃ¡t hiá»‡n fraud patterns phá»©c táº¡p
- CÃ³ thá»ƒ cháº­m vá»›i dataset lá»›n

# Ká»³ vá»ng:
- MI cÃ³ thá»ƒ chá»n Time/Amount
- ANOVA chá»n V1-V28 components
```

### Cardiovascular Dataset
```python
# Features: age, BMI, BP, cholesterol, etc.
# Total: 15 features

# ANOVA F-test:
- Tá»‘t cho continuous features
- Nhanh vá»›i 70k rows

# Mutual Information:
- PhÃ¡t hiá»‡n interactions (BMI Ã— age)
- Tá»‘t cho categorical features
- Robust vá»›i outliers

# Ká»³ vá»ng:
- MI chá»n features cÃ³ interaction
- ANOVA chá»n features cÃ³ correlation máº¡nh
```

## ğŸ“Š Káº¿t Quáº£ Mong Äá»£i

### Scenario 1: ANOVA vÃ  MI chá»n features giá»‘ng nhau
```
Model: Gen3_XGBoost
select_k_best_5:  ['age', 'BMI', 'ap_hi', 'ap_lo', 'cholesterol']
mutual_info_5:    ['age', 'BMI', 'ap_hi', 'ap_lo', 'cholesterol']
Performance:      TÆ¯Æ NG ÄÆ¯Æ NG

â†’ Quan há»‡ tuyáº¿n tÃ­nh, Ä‘Æ¡n giáº£n
```

### Scenario 2: MI chá»n features khÃ¡c (Tá»T HÆ N)
```
Model: Gen2_RandomForest
select_k_best_5:  ['age', 'BMI', 'ap_hi', 'ap_lo', 'cholesterol']
mutual_info_5:    ['age', 'BMI', 'pulse_pressure', 'MAP', 'ageÃ—BMI']
Performance:      MI > ANOVA (+2-3% PR-AUC)

â†’ PhÃ¡t hiá»‡n Ä‘Æ°á»£c interactions!
```

### Scenario 3: ANOVA tá»‘t hÆ¡n (dataset Ä‘Æ¡n giáº£n)
```
Model: Gen1_LogisticRegression  
select_k_best_5:  ['age', 'BMI', 'ap_hi', 'ap_lo', 'cholesterol']
mutual_info_5:    ['age', 'weight', 'height', 'ap_hi', 'ap_lo']
Performance:      ANOVA > MI (+1% PR-AUC)

â†’ Linear model prefer linear features
```

## ğŸš€ CÃ¡ch Cháº¡y

### Full Run (All 270 Experiments)
```bash
# Cardio dataset
python full_comparison.py --data data/raw/cardio_train.csv

# Creditcard dataset  
python full_comparison.py --data data/raw/creditcard.csv
```

### Vá»›i Cache (Recommended)
```bash
# Chá»‰ train experiments má»›i (mutual_info_*)
# Experiments cÅ© load tá»« cache
python full_comparison.py --data data/raw/cardio_train.csv

# Output:
# [1/270] Gen1_LogisticRegression | mutual_info_5 | ...
#   âš™ï¸  Training... (experiment má»›i)
# [2/270] Gen1_LogisticRegression | select_k_best_5 | ...
#   âœ“ Loaded from cache! (experiment cÅ©)
```

### No Cache (Train All)
```bash
python full_comparison.py --data data/raw/cardio_train.csv --no-cache
```

## ğŸ“ Output Structure

```
experiments/
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ cardio_train_20251016_HHMMSS.log
â”‚   â””â”€â”€ creditcard_20251016_HHMMSS.log
â”œâ”€â”€ full_comparison/
â”‚   â”œâ”€â”€ cardio_train/
â”‚   â”‚   â”œâ”€â”€ full_comparison_20251016_HHMMSS.csv
â”‚   â”‚   â””â”€â”€ best_model/
â”‚   â””â”€â”€ creditcard/
â”‚       â”œâ”€â”€ full_comparison_20251016_HHMMSS.csv
â”‚       â””â”€â”€ best_model/
â””â”€â”€ model_cache/
    â”œâ”€â”€ cardio_train/
    â”‚   â”œâ”€â”€ Gen1_KNN_..._mutual_info_5_abc.pkl  â­ NEW
    â”‚   â”œâ”€â”€ Gen1_KNN_..._mutual_info_12_def.pkl â­ NEW
    â”‚   â””â”€â”€ ... (existing cache files)
    â””â”€â”€ creditcard/
        â””â”€â”€ ... (same structure)
```

## ğŸ” PhÃ¢n TÃ­ch Káº¿t Quáº£

### 1. So SÃ¡nh ANOVA vs MI
```python
import pandas as pd

df = pd.read_csv('experiments/full_comparison/cardio_train/full_comparison_*.csv')

# Group by model and feature selection method
comparison = df.groupby(['model', 'feature_selection'])['pr_auc'].mean().unstack()

# Compare k=5
print(comparison[['select_k_best_5', 'mutual_info_5']])

# Which is better?
better = (comparison['mutual_info_5'] > comparison['select_k_best_5']).sum()
print(f"Mutual Info tá»‘t hÆ¡n á»Ÿ {better}/{len(comparison)} models")
```

### 2. Feature Importance Comparison
```python
# Features chá»n bá»Ÿi ANOVA
anova_features = get_selected_features('select_k_best_5')

# Features chá»n bá»Ÿi MI
mi_features = get_selected_features('mutual_info_5')

# So sÃ¡nh
print(f"Overlap: {len(set(anova_features) & set(mi_features))} features")
print(f"Only ANOVA: {set(anova_features) - set(mi_features)}")
print(f"Only MI: {set(mi_features) - set(anova_features)}")
```

### 3. Best Method Per Model
```python
# TÃ¬m method tá»‘t nháº¥t cho má»—i model
best_methods = df.groupby('model').apply(
    lambda x: x.loc[x['pr_auc'].idxmax(), 'feature_selection']
)

print(best_methods.value_counts())
# Output:
# mutual_info_5     5 models
# mutual_info_12    3 models  
# select_k_best_5   3 models
# select_k_best_12  2 models
# none              0 models
```

## âš ï¸ LÆ°u Ã Quan Trá»ng

### 1. Mutual Information Cháº­m HÆ¡n
- MI cÃ³ thá»ƒ cháº­m gáº¥p 2-5 láº§n ANOVA
- Vá»›i dataset lá»›n (>200k rows), cÃ³ thá»ƒ máº¥t vÃ i phÃºt
- Sá»­ dá»¥ng cache Ä‘á»ƒ trÃ¡nh train láº¡i

### 2. Random Seed
```python
# MI cÃ³ element stochastic
mutual_info_classif(X, y, random_state=42)  # Äáº£m báº£o reproducibility
```

### 3. Feature Scaling
- ANOVA: KhÃ´ng nháº¡y cáº£m vá»›i scale
- MI: **NHáº Y Cáº¢M** vá»›i scale
- â†’ NÃªn scale trÆ°á»›c khi dÃ¹ng MI

### 4. Small Sample Size
- MI cáº§n Ã­t nháº¥t ~100 samples per feature
- Vá»›i k=12, cáº§n >1200 samples
- Dataset cá»§a chÃºng ta: 70k (cardio), 285k (credit) â†’ OK âœ…

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

### Papers
1. **Mutual Information Feature Selection**
   - Cover & Thomas (1991) - Elements of Information Theory
   
2. **ANOVA F-test**
   - Fisher (1925) - Statistical Methods for Research Workers

### Scikit-learn Documentation
- [`mutual_info_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)
- [`f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html)

## ğŸ‰ TÃ³m Táº¯t

âœ… **ÄÃ£ thÃªm:** `mutual_info_5` vÃ  `mutual_info_12`  
âœ… **Tá»•ng experiments:** 162 â†’ 270 (+108, +67%)  
âœ… **Thá»i gian thÃªm:** ~81 phÃºt (~1.4 giá»)  
âœ… **Lá»£i Ã­ch:** PhÃ¡t hiá»‡n non-linear feature relationships  
âœ… **Compatible:** Hoáº¡t Ä‘á»™ng vá»›i má»i models vÃ  datasets  
âœ… **Cache-friendly:** Chá»‰ train experiments má»›i  

---

**Next Steps:**
1. âœ… Cháº¡y full comparison vá»›i mutual info
2. â³ PhÃ¢n tÃ­ch features Ä‘Æ°á»£c chá»n
3. â³ So sÃ¡nh performance ANOVA vs MI
4. â³ Document insights

**Date:** 2025-10-16  
**Version:** 3.0 (Baseline â†’ K=5 â†’ Mutual Info)
